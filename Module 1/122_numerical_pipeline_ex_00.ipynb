{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1489225",
   "metadata": {},
   "source": [
    "# üìù Exercise M1.02\n",
    "\n",
    "The goal of this exercise is to fit a similar model as in the previous\n",
    "notebook to get familiar with manipulating scikit-learn objects and in\n",
    "particular the `.fit/.predict/.score` API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ed284",
   "metadata": {},
   "source": [
    "Let's load the adult census dataset with only numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d88d3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census-numeric.csv\")\n",
    "data = adult_census.drop(columns=\"class\")\n",
    "target = adult_census[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b0a164",
   "metadata": {},
   "source": [
    "In the previous notebook we used `model = KNeighborsClassifier()`. All\n",
    "scikit-learn models can be created without arguments. This is convenient\n",
    "because it means that you don't need to understand the full details of a model\n",
    "before starting to use it.\n",
    "\n",
    "One of the `KNeighborsClassifier` parameters is `n_neighbors`. It controls the\n",
    "number of neighbors we are going to use to make a prediction for a new data\n",
    "point.\n",
    "\n",
    "What is the default value of the `n_neighbors` parameter?\n",
    "\n",
    "**Hint**: Look at the documentation on the [scikit-learn\n",
    "website](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "or directly access the description inside your notebook by running the\n",
    "following cell. This opens a pager pointing to the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a6e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minkowski'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetric_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Classifier implementing the k-nearest neighbors vote.\n",
      "\n",
      "Read more in the :ref:`User Guide <classification>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_neighbors : int, default=5\n",
      "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      "\n",
      "weights : {'uniform', 'distance'}, callable or None, default='uniform'\n",
      "    Weight function used in prediction.  Possible values:\n",
      "\n",
      "    - 'uniform' : uniform weights.  All points in each neighborhood\n",
      "      are weighted equally.\n",
      "    - 'distance' : weight points by the inverse of their distance.\n",
      "      in this case, closer neighbors of a query point will have a\n",
      "      greater influence than neighbors which are further away.\n",
      "    - [callable] : a user-defined function which accepts an\n",
      "      array of distances, and returns an array of the same shape\n",
      "      containing the weights.\n",
      "\n",
      "algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      "    Algorithm used to compute the nearest neighbors:\n",
      "\n",
      "    - 'ball_tree' will use :class:`BallTree`\n",
      "    - 'kd_tree' will use :class:`KDTree`\n",
      "    - 'brute' will use a brute-force search.\n",
      "    - 'auto' will attempt to decide the most appropriate algorithm\n",
      "      based on the values passed to :meth:`fit` method.\n",
      "\n",
      "    Note: fitting on sparse input will override the setting of\n",
      "    this parameter, using brute force.\n",
      "\n",
      "leaf_size : int, default=30\n",
      "    Leaf size passed to BallTree or KDTree.  This can affect the\n",
      "    speed of the construction and query, as well as the memory\n",
      "    required to store the tree.  The optimal value depends on the\n",
      "    nature of the problem.\n",
      "\n",
      "p : int, default=2\n",
      "    Power parameter for the Minkowski metric. When p = 1, this is\n",
      "    equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      "    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      "\n",
      "metric : str or callable, default='minkowski'\n",
      "    Metric to use for distance computation. Default is \"minkowski\", which\n",
      "    results in the standard Euclidean distance when p = 2. See the\n",
      "    documentation of `scipy.spatial.distance\n",
      "    <https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and\n",
      "    the metrics listed in\n",
      "    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric\n",
      "    values.\n",
      "\n",
      "    If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      "    must be square during fit. X may be a :term:`sparse graph`, in which\n",
      "    case only \"nonzero\" elements may be considered neighbors.\n",
      "\n",
      "    If metric is a callable function, it takes two arrays representing 1D\n",
      "    vectors as inputs and must return one value indicating the distance\n",
      "    between those vectors. This works for Scipy's metrics, but is less\n",
      "    efficient than passing the metric name as a string.\n",
      "\n",
      "metric_params : dict, default=None\n",
      "    Additional keyword arguments for the metric function.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of parallel jobs to run for neighbors search.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "    Doesn't affect :meth:`fit` method.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "classes_ : array of shape (n_classes,)\n",
      "    Class labels known to the classifier\n",
      "\n",
      "effective_metric_ : str or callble\n",
      "    The distance metric used. It will be same as the `metric` parameter\n",
      "    or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      "    'minkowski' and `p` parameter set to 2.\n",
      "\n",
      "effective_metric_params_ : dict\n",
      "    Additional keyword arguments for the metric function. For most metrics\n",
      "    will be same with `metric_params` parameter, but may also contain the\n",
      "    `p` parameter value if the `effective_metric_` attribute is set to\n",
      "    'minkowski'.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_samples_fit_ : int\n",
      "    Number of samples in the fitted data.\n",
      "\n",
      "outputs_2d_ : bool\n",
      "    False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
      "    otherwise True.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
      "KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
      "RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
      "NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      "for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      "\n",
      ".. warning::\n",
      "\n",
      "   Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      "   neighbors, neighbor `k+1` and `k`, have identical distances\n",
      "   but different labels, the results will depend on the ordering of the\n",
      "   training data.\n",
      "\n",
      "https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> X = [[0], [1], [2], [3]]\n",
      ">>> y = [0, 0, 1, 1]\n",
      ">>> from sklearn.neighbors import KNeighborsClassifier\n",
      ">>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      ">>> neigh.fit(X, y)\n",
      "KNeighborsClassifier(...)\n",
      ">>> print(neigh.predict([[1.1]]))\n",
      "[0]\n",
      ">>> print(neigh.predict_proba([[0.9]]))\n",
      "[[0.666... 0.333...]]\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\program files\\python311\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f75ce49",
   "metadata": {},
   "source": [
    "Create a `KNeighborsClassifier` model with `n_neighbors=50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed1e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "model = KNeighborsClassifier(n_neighbors=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2b275",
   "metadata": {},
   "source": [
    "Fit this model on the data and target loaded above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbbdbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "_ = model.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c1b19f",
   "metadata": {},
   "source": [
    "Use your model to make predictions on the first 10 data points inside the\n",
    "data. Do they match the actual target values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21cced1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2     True\n",
       "3     True\n",
       "4     True\n",
       "5     True\n",
       "6     True\n",
       "7     True\n",
       "8     True\n",
       "9    False\n",
       "Name: class, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "target_predicted = model.predict(data[:10])\n",
    "target[:10] == target_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2946586b",
   "metadata": {},
   "source": [
    "Compute the accuracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a266716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 82.90%\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "accuracy = model.score(data, target)\n",
    "print(f\"The accuracy is {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9c600",
   "metadata": {},
   "source": [
    "Now load the test data from `\"../datasets/adult-census-numeric-test.csv\"` and\n",
    "compute the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac43675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 81.88%\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "\n",
    "adult_census_test = pd.read_csv(\"../datasets/adult-census-numeric-test.csv\")\n",
    "\n",
    "target_test = adult_census_test[\"class\"]\n",
    "data_test = adult_census_test.drop(columns=[\"class\"])\n",
    "\n",
    "accuracy = model.score(data_test, target_test)\n",
    "print(f\"The accuracy is {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbreset": "https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/main/notebooks/02_numerical_pipeline_ex_00.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
