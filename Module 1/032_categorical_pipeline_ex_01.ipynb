{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a9fe43",
   "metadata": {},
   "source": [
    "# üìù Exercise M1.04\n",
    "\n",
    "The goal of this exercise is to evaluate the impact of using an arbitrary\n",
    "integer encoding for categorical variables along with a linear classification\n",
    "model such as Logistic Regression.\n",
    "\n",
    "To do so, let's try to use `OrdinalEncoder` to preprocess the categorical\n",
    "variables. This preprocessor is assembled in a pipeline with\n",
    "`LogisticRegression`. The generalization performance of the pipeline can be\n",
    "evaluated by cross-validation and then compared to the score obtained when\n",
    "using `OneHotEncoder` or to some other baseline score.\n",
    "\n",
    "First, we load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a92cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d621ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"class\"\n",
    "target = adult_census[target_name]\n",
    "data = adult_census.drop(columns=[target_name, \"education-num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d68716",
   "metadata": {},
   "source": [
    "In the previous notebook, we used `sklearn.compose.make_column_selector` to\n",
    "automatically select columns with a specific data type (also called `dtype`).\n",
    "Here, we use this selector to get only the columns containing strings (column\n",
    "with `object` dtype) that correspond to categorical features in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e791f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "data_categorical = data[categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ece710",
   "metadata": {},
   "source": [
    "Define a scikit-learn pipeline composed of an `OrdinalEncoder` and a\n",
    "`LogisticRegression` classifier.\n",
    "\n",
    "Because `OrdinalEncoder` can raise errors if it sees an unknown category at\n",
    "prediction time, you can set the `handle_unknown=\"use_encoded_value\"` and\n",
    "`unknown_value` parameters. You can refer to the [scikit-learn\n",
    "documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)\n",
    "for more details regarding these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">My Note</p>\n",
    "<p>\n",
    "OrdinalEncoder will replace unknown values with np.nan. This will lead to an error in the LogisticRegression. We can use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html\">KNNImputer</a> to impute missing values.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdf47e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "# Write your code here.\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan).set_output(transform=\"pandas\")\n",
    "\n",
    "model = make_pipeline(encoder, KNNImputer(), LogisticRegression(max_iter=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82451f04",
   "metadata": {},
   "source": [
    "Your model is now defined. Evaluate it using a cross-validation using\n",
    "`sklearn.model_selection.cross_validate`.\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">Be aware that if an error happened during the cross-validation,\n",
    "<tt class=\"docutils literal\">cross_validate</tt> would raise a warning and return NaN (Not a Number) as scores.\n",
    "To make it raise a standard Python exception with a traceback, you can pass\n",
    "the <tt class=\"docutils literal\"><span class=\"pre\">error_score=\"raise\"</span></tt> argument in the call to <tt class=\"docutils literal\">cross_validate</tt>. An\n",
    "exception would be raised instead of a warning at the first encountered problem\n",
    "and <tt class=\"docutils literal\">cross_validate</tt> would stop right away instead of returning NaN values.\n",
    "This is particularly handy when developing complex machine learning pipelines.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebd14076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:       [0.44135189 0.27168274 0.36635756 0.38192868 0.32005858]\n",
      "score_time:     [0.03015709 0.03336787 0.03326845 0.03409624 0.02983809]\n",
      "test_score:     [0.75514382 0.75555328 0.75573301 0.75307125 0.75788288]\n",
      "The accuracy is: 0.755 ¬± 0.002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Write your code here.\n",
    "cv_results = cross_validate(model, data_categorical, target)\n",
    "for key, values in cv_results.items():\n",
    "    print(f\"{key+':':<15} {values}\")\n",
    "scores = cv_results[\"test_score\"]\n",
    "print(f\"The accuracy is: {scores.mean():.3f} ¬± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ecc5c4",
   "metadata": {},
   "source": [
    "Now, we would like to compare the generalization performance of our previous\n",
    "model with a new model where instead of using an `OrdinalEncoder`, we use a\n",
    "`OneHotEncoder`. Repeat the model evaluation using cross-validation. Compare\n",
    "the score of both models and conclude on the impact of choosing a specific\n",
    "encoding strategy when using a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "babb2e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time:       [0.70531893 0.71347737 0.632792   0.71288228 0.6841476 ]\n",
      "score_time:     [0.02020502 0.01551723 0.03628802 0.03337145 0.03082418]\n",
      "test_score:     [0.83222438 0.83560242 0.82872645 0.83312858 0.83466421]\n",
      "The accuracy is: 0.833 ¬± 0.002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Write your code here.\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "model = make_pipeline(encoder, LogisticRegression(max_iter=500))\n",
    "cv_results = cross_validate(model, data_categorical, target)\n",
    "for key, values in cv_results.items():\n",
    "    print(f\"{key+':':<15} {values}\")\n",
    "scores = cv_results[\"test_score\"]\n",
    "print(f\"The accuracy is: {scores.mean():.3f} ¬± {scores.std():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbreset": "https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/main/notebooks/03_categorical_pipeline_ex_01.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
